지난 시간 복습

# 미리 띄워놓아야 할 것
데스모스 (다중회귀, 로지스틱회귀, 로지스틱, 로지스틱 손실1, 로지스틱 손실2)
Day3 회귀 PPT
Day3 분류 PPT
Day3 회귀 실습1 터미널 
Day4  분류 실습1 터미널


1. Day3  회귀
# 26 다중 회귀 
	> 수식으로 선형, 다항도 잠깐 설명
	> 선형회귀 식의 의미
	> 선형이란 무엇인가?  

# 데스모스  (다중회귀) 먼저 보여준다
	다중회귀는 계수가 2개인 경우 3차원 공간에서 예측값들이 어떤 평면위에 모두 놓인다.

# 61, 62, 65  모델이 학습한 평면(단순선형회귀에선 직선) 과 테스트 샘플들의 오차가 모델의 성능이 된다.
	학습에선 이걸 MSE 를 최소화하는 방식으로 업데이트 

# 15, 16 (경사하강법을 쓸수 있고 정규방정식, QR 분해 SVD도 가능)
	즉 모델 예측값은 선형회귀식의 선형결합이 되고
	손실함수는 MSE, 계수에 대해 손실함수를 미분한 값으로 계수를 업데이트
	(경사하강법 빠르게 설명-데스모스 다중회귀 그래프 돌려놓고) 

2. Day4 분류
# 10, 11, 12
	> 로지스틱 회귀란 무엇인가?
	> 선형회귀와 시그모이드의 만남 배경 설명

# 13 승산비와 로그오즈(로짓) 소개. 시그모이드 함수와 로지스틱 함수 소개

# 데스모스(로지스틱) 보여주면서 승산비, 로그오즈, 로지스틱 함수 설명
# 데스모스(로지스틱 회귀) 보여주면서 돌려놓고 설명
	로지스틱 회귀는 계수가 2개인 경우 3차원 공간에서 예측값들이 어떤 곡면 위에 놓이면서
	 σ(z) = 0.5일 때 z=0 즉 ax+by+c=0 이되는 x, y의 조합이 직선의 결정경계를 만든다.

# 데스모스(로지스틱 손실1) 보여주면서 로지스틱 손실함수 설명 
	이진분류를 한다고 하면 타깃이 1일 때  모델예측값이 1에 가까우면 -log(p) 가 최소화 되고
	타깃이 0일때 모델 예측값이 0에 가까우면 -log(1-p)  가 최소화 되니까
	-[ylogp + (1-y)log(1-p)] 이걸 최소화 시키면 된다. 이게 BCE
	
# 데스모스(로지스틱 손실2) 보여준다
	다시 경사하강법 설명 

# Day3  회귀 실습1 터미널 손실함수 미분해서 경사하강법으로 계수 업데이트 한걸 구현한 것 
# Day4  분류 실습1 터미널  logistic_model = LogisticRegression(solver="saga")

3. Day3 회귀 

# 46 정규화 설명 (규제란 표현이 더 맞다)
# 55 정규화항 보여주고 칠판에 릿지랑 라쏘 그려줄 것
	규제는 피쳐에 곱해지는 계수의 크기를 줄인다.
	규제 전엔 반드시 정규화를 해주는 게 좋다 (여기서 표준화 설명해줄것)
	피쳐 스케일이 다른데 규제를 하면 피쳐마다 규제가 다르게 적용되므로
	L1이 라쏘(계수들의 절대값 합을 최소화), L2가 릿지(계수들의 제곱합을 최소화)
	MSE 오차제곱합 손실에 더해지는 규제항 설명, 람다 설명
	람다가 클수록 전체 손실이 작아지려면 규제항이 더 작아져야 한다.
	규제가 있게 되면 모델이 경사하강법 업데이트로 가질수 있는 최적 계수를
	규제허용범위를 넘어서서 가질수 없게 된다 (규제가 강하면 원이 더 작아진다.)
	보통 손실함수를 최소화 하는 계수는 크기가 큰 경우가 많다.


4. Day5로 넘어가기 전에
	모델 설명가능성에 대해 설명
	회귀, 즉 선형모델은 데이터가 어떤 형태를 따른다고 가정한다.
	데이터 분포가 선형이라든지, 결정경계가 선형이라든지.
	하지만 계수와 절편이 왜 그러한 값을 가지게 되었는지 설명하기 힘들다.
	이런걸 모수모델이라고 한다.

	오늘 배울건 비모수모델. 데이터가 특정분포를 띈다는 가정을 하지 않는 모델.
	데이터에서 직접 패턴을 찾는 모델.
	이게 왜 더 모델의 설명가능성을, 모델이 내놓은 결과에 대한 해석을 용이하게 하는가.
